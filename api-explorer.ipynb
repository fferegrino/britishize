{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6606bd-fb48-4ed8-afb0-5168569f6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = \"sk-\"\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0.1 # Value between 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b4a08-79f5-4ab3-837e-7890f03859d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116ff4c-88b4-4602-ae40-2116c170b575",
   "metadata": {},
   "source": [
    "## The message structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329125d8-16e8-4f3d-b4fb-69cd3e2932fb",
   "metadata": {},
   "source": [
    "The way these models work is through a conversation interface, this conversation engine works through a series of messages in the format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"message\"\n",
    "}\n",
    "```\n",
    "\n",
    "As far as roles go, there are three:\n",
    "\n",
    " - \"user\"\n",
    " - \"assistant\"\n",
    " - \"system\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54811eb3-da57-422f-a91d-e15b1476401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    { \"role\": \"user\", \"content\": \"Who are you?\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b76d5-1386-48d9-86f9-82b1f8c1e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = client.chat.completions.create(\n",
    "    model = OPENAI_MODEL,\n",
    "    temperature = TEMPERATURE,\n",
    "    messages = messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97391fb0-a3a7-44f0-aa69-e8d1d525cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1726e16-ae7d-48ff-af90-99a68b857f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_choice = completions.choices[0]\n",
    "message_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bc7ce-7c68-4cb5-896f-ecb380957b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_choice.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2b479-a1b9-406d-8b68-3692fb555dc8",
   "metadata": {},
   "source": [
    "## The `system` role\n",
    "\n",
    "It is possible to use a *\"system\"* message to customise the assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19158aa7-3701-4b0c-ab1a-54f90dbf10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are Spaghetti Rigatoni, a high-cusine chef that is always preparing something tasty\"\n",
    "    },\n",
    "    { \"role\": \"user\", \"content\": \"Who are you?\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ceb09-7ff0-4ad3-af5d-0837577048b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = client.chat.completions.create(\n",
    "    model = OPENAI_MODEL,\n",
    "    temperature = TEMPERATURE,\n",
    "    messages = messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8defb92-1569-4c54-830c-8ec99f2ff0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c56487-40d3-4c9c-82c0-b63e3777d7d3",
   "metadata": {},
   "source": [
    "## A helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a004e-eb3b-4400-b696-501f876eb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = \"sk-\"\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0.1 # Value between 0 and 2\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_response(prompt):\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": prompt }\n",
    "    ]\n",
    "    completions = client.chat.completions.create(\n",
    "        model = OPENAI_MODEL,\n",
    "        temperature = TEMPERATURE,\n",
    "        messages = messages,\n",
    "    )\n",
    "    return completions.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffaa0c0-ebd6-419a-9386-03c606e2e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(\"Hello, my name is Antonio. Who are you?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d321d-a993-4e1f-93ae-de3ec60aaf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
